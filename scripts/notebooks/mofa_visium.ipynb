{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOFA Pipeline\n",
    "\n",
    "- Here is a useful tutorial to get started running MOFApy: https://github.com/bioFAM/mofapy2/blob/master/mofapy2/notebooks/getting_started_python.ipynb\n",
    "\n",
    "- Here is a useful tutorial to evaluate the MOFApy results using mofax: https://github.com/bioFAM/mofax/blob/master/notebooks/getting_started_pbmc10k.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofapy2.run.entry_point import entry_point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scanpy as sc\n",
    "import mofax as mfx\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import decoupler as dc\n",
    "import plotnine as pn\n",
    "\n",
    "from composition_stats import closure, ilr\n",
    "\n",
    "# initialise the entry point\n",
    "ent = entry_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"cellbender\"\n",
    "deconv_model = \"all\"\n",
    "dc_model = \"ulm\"\n",
    "ct_metric = \"abunds\"\n",
    "image_features = \"None\"\n",
    "n_factors = 10\n",
    "recompute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: hallmarks are always used\n",
    "obsm_to_use = []\n",
    "#TODO: rerun process and remove this line\n",
    "#obsm_to_use.append(f\"hallmark_{dc_model}_estimates\")\n",
    "if dc_model == \"ulm\":\n",
    "    obsm_to_use.append(\"hallmark_ulm_estimates\") # see here \"estimates\"\n",
    "elif dc_model == \"wmean\":\n",
    "    obsm_to_use.append(\"hallmark_wmean_estimate\") # see here \"estimate\"\n",
    "\n",
    "if image_features != \"None\":\n",
    "    obsm_to_use.append(image_features)\n",
    "\n",
    "obsm_to_use.append(f\"{ct_metric}_{deconv_model}\")\n",
    "\n",
    "print(f\"Using the following views: {obsm_to_use}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the paths\n",
    "current_path = globals()[\"_dh\"][0]\n",
    "out_dir = current_path / \"..\" / \"..\" / \"data\" / \"prc\" / \"vis\" / \"mofa_tests\" / output / f\"{deconv_model}__{ct_metric}__{dc_model}__{image_features}__{str(n_factors)}\"\n",
    "plot_dir = out_dir / \"plots\"\n",
    "sc.settings.figdir = str(plot_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "plot_dir.mkdir(parents=True, exist_ok=True) \n",
    "visium_path = current_path / \"..\" / \"..\" / \"data\" / \"prc\" / \"vis\" / \"processed\" / output\n",
    "visium_samples = [f.split(\".\")[0] for f in os.listdir(visium_path) if not f.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta = pd.read_excel(current_path / \"..\" / \"..\" / \"data\" / \"Metadata_all.xlsx\", sheet_name=\"Visium\")\n",
    "sample_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dict = {smp: sc.read_h5ad(visium_path / f\"{smp}.h5ad\") for smp in visium_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = visium_samples[0]\n",
    "print(first_sample)\n",
    "vis_dict[first_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dict[first_sample].obsm_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scatterplot\n",
    "plt.scatter(vis_dict[\"MS549H\"].obsm[\"abunds_all\"].sum(axis=0), vis_dict[\"MS497I\"].obsm[\"abunds_all\"].sum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_to_use = [\"abunds_all\", \"hallmark_ulm_estimates\"]\n",
    "#obsm_to_use = [\"abunds_all\", \"hallmark_estimates\", \"summary\"]\n",
    "#obsm_to_use = [\"props_all_ilr\", \"hallmark_estimates\"]\n",
    "assert np.all(np.isin(obsm_to_use, vis_dict[first_sample].obsm_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dict[first_sample].obsm[\"abunds_all\"].shape[1], vis_dict[first_sample].obsm[\"props_ilr_all\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: temporary fix to put the ilr transformed data into a dataframe\n",
    "# NOTE: It is important that the column names do not resemble integers otherwise there are hd5 errors when saving the MOFA model\n",
    "for values in vis_dict.values():\n",
    "    values.obsm[\"props_ilr_all\"] = pd.DataFrame(values.obsm[\"props_ilr_all\"], index=values.obs.index, \n",
    "                                                columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_all\"].shape[1]))])\n",
    "    values.obsm[\"props_ilr_condition\"] = pd.DataFrame(values.obsm[\"props_ilr_condition\"], index=values.obs.index, \n",
    "                                                      columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_condition\"].shape[1]))])\n",
    "    #values.obsm[\"props_ilr_lesion_type\"] = pd.DataFrame(values.obsm[\"props_ilr_lesion_type\"], index=values.obs.index, \n",
    "    #                                                    columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_lesion_type\"].shape[1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(visium_samples[0])\n",
    "print(f\"Adata object for first visium sample:\\n{vis_dict[visium_samples[0]]}\")\n",
    "print(f\"Available obsm layers:\\n{vis_dict[visium_samples[0]].obsm_keys()}\")\n",
    "obsm_features = {obsm_key: vis_dict[visium_samples[0]].obsm[obsm_key].columns.to_list() for obsm_key in obsm_to_use}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cell metadata\n",
    "meta_list = []\n",
    "for sample in visium_samples:\n",
    "    df = vis_dict[sample].obs.copy()\n",
    "    df.index = [sample + \"_\" + s for s in df.index]\n",
    "    df[\"sample_id\"] = sample\n",
    "    df[\"condition\"] = sample_meta.loc[sample_meta.sample_id == sample, \"Condition\"].values[0]\n",
    "    df[\"lesion_type\"] = sample_meta.loc[sample_meta.sample_id == sample, \"lesion_type\"].values[0]\n",
    "    meta_list.append(df)\n",
    "meta_df = pd.concat(meta_list, axis=0)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mofa dataframe\n",
    "df_list = []\n",
    "for obsm_key in obsm_to_use:\n",
    "    for sample in visium_samples:\n",
    "        df = vis_dict[sample].obsm[obsm_key].copy()\n",
    "        df.index = [sample + \"_\" + s for s in df.index] # unique barcodes are required!\n",
    "        df = df.reset_index().melt(id_vars=\"index\", var_name=\"feature\", value_name=\"value\")\n",
    "        df = df.rename(columns={\"index\": \"sample\"})\n",
    "        df[\"group\"] = sample\n",
    "        df[\"view\"] = obsm_key\n",
    "        df = df[[\"sample\", \"group\", \"feature\", \"value\", \"view\"]]\n",
    "        df_list.append(df)\n",
    "data_dt = pd.concat(df_list)\n",
    "print(\"Mofa dataframe:\\n\")\n",
    "print(data_dt.head())\n",
    "print(data_dt.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale each view to unit variance\n",
    "ent.set_data_options(\n",
    "    scale_views = True\n",
    ")\n",
    "\n",
    "# set the likelihoods for all views\n",
    "ent.set_data_df(data_dt, likelihoods = [\"gaussian\" for _ in range(len(obsm_to_use))])\n",
    "\n",
    "# set the model options\n",
    "ent.set_model_options(\n",
    "    factors = 10,\n",
    "    spikeslab_weights = True, \n",
    "    ard_weights = True\n",
    ")\n",
    "\n",
    "# set the training options\n",
    "ent.set_train_options(\n",
    "    convergence_mode = \"fast\", \n",
    "    dropR2 = 0.001, \n",
    "    gpu_mode = True, \n",
    "    seed = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent.data_opts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent.save(outfile=str(out_dir / \"mofa_model.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mfx.mofa_model(out_dir / \"mofa_model.hdf5\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\\\n",
    "Cells: {model.shape[0]}\n",
    "Features: {model.shape[1]}\n",
    "Groups of cells: {', '.join(model.groups)}\n",
    "Views: {', '.join(model.views)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adata object based on MOFA results\n",
    "adata = sc.AnnData(X=model.get_factors())\n",
    "adata.obs = model.get_cells()\n",
    "adata.obs.set_index(\"cell\", inplace=True)\n",
    "sc.pp.neighbors(adata, n_neighbors=15, use_rep=\"X\")\n",
    "resolutions = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "for res in resolutions:\n",
    "    sc.tl.leiden(adata, resolution=res, key_added=f\"leiden_{res}\")\n",
    "adata.obs.rename(columns={\"group\": \"sample_id\"}, inplace=True)\n",
    "adata.obs = adata.obs.join(sample_meta.set_index(\"sample_id\"), on=\"sample_id\")\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "for obsm_key in obsm_to_use:\n",
    "    df_list = []\n",
    "    for sample in visium_samples:\n",
    "        df = vis_dict[sample].obsm[obsm_key].copy()\n",
    "        df.index = [sample + \"_\" + s for s in df.index] # unique barcodes are required!\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list)\n",
    "    adata.obsm[obsm_key] = df.loc[adata.obs_names]\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(out_dir / \"adata.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"sample_id\", \"Condition\", \"leiden_0.5\"], ncols=1, save=\".pdf\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the cluster fractions per sample, pca, and visualize\n",
    "for res in resolutions:\n",
    "    df = adata.obs.copy()\n",
    "    df = df.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df += 1 # adding pseudocount otherwise ilr breaks (returns NA)\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "    # remove outlier sample MS94\n",
    "    df = df.loc[df.index != \"MS94\"]\n",
    "\n",
    "    # apply ilr (first check and ensure closure)\n",
    "    df.loc[:, :] = closure(df.values)\n",
    "    assert np.all(np.isclose(df.values.sum(axis=1), 1))\n",
    "    df_ilr = ilr(df.values)\n",
    "\n",
    "    pca = PCA(n_components=df_ilr.shape[1])\n",
    "    pca.fit(df_ilr)\n",
    "    pca_df = pd.DataFrame(pca.transform(df_ilr)[:,[0,1,2,3]], index=df.index, columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\"])\n",
    "    pca_df[\"sample_id\"] = pca_df.index.get_level_values(0)\n",
    "    pca_df.set_index(\"sample_id\", inplace=True)\n",
    "    pca_df = pca_df.join(sample_meta.set_index(\"sample_id\"),  on=\"sample_id\", how=\"left\", lsuffix=\"_pca\", rsuffix=\"_meta\")\n",
    "    pca_df = pca_df.reset_index()\n",
    "    pca_df.Batch = [str(b) for b in pca_df.Batch]\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(14, 12))\n",
    "    ax = ax.flatten()\n",
    "    for axis, label in zip(ax, [\"Condition\", \"lesion_type\", \"Batch\", \"Sex\", \"Age\", \"lesion_type\"]):\n",
    "        sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=label, ax=axis)\n",
    "        axis.set_title(f\"PCA on Cluster Proportions, colored by {label}\")\n",
    "        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        axis.set_xlabel(f\"PC1: {np.round(pca.explained_variance_ratio_[0], 2)}\")\n",
    "        axis.set_ylabel(f\"PC2: {np.round(pca.explained_variance_ratio_[1], 2)}\")\n",
    "        fig.tight_layout()\n",
    "        axis.set_aspect('equal', 'box')\n",
    "    # plot sample_id labels\n",
    "    for string, x, y in zip(pca_df.sample_id, pca_df.PC1, pca_df.PC2):\n",
    "        ax[5].text(x, y, string)\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_pca_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the cluster fractions per sample, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Sample ID\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per sample (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_sample_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the cluster fractions per lesion type, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"lesion_type\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Lesion Type\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per lesion type (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_lesion_type_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the cluster fractions per condition, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"Condition\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Condition\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per condition (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_condition_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement what we have been taling about in the meeting with Pau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obsm_key = obsm_to_use[0]\n",
    "#res = resolutions[0]\n",
    "obsm_key = \"abunds_all\"\n",
    "res = 0.5\n",
    "obsm_key, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"abunds\" in obsm_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obsm[obsm_key].copy()\n",
    "meta_keys = [\"sample_id\", \"Condition\", \"lesion_type\"] + [\"leiden_\" + str(res) for res in resolutions]\n",
    "df = df.join(adata.obs[meta_keys], on=\"cell\")\n",
    "df.reset_index(inplace=True)\n",
    "df = df.melt(id_vars=[\"cell\"]+meta_keys, var_name=\"feature\", value_name=\"value\")\n",
    "assert df.value.isna().sum() == 0\n",
    "if \"abunds\" in obsm_key:\n",
    "    # use proportions instead of abundances for cell types\n",
    "    df[\"value\"] = df.groupby([\"cell\"])[\"value\"].transform(lambda x: x / x.sum())\n",
    "df = df.groupby([\"sample_id\", f\"leiden_{res}\", \"feature\"]).mean().reset_index()\n",
    "df.value.fillna(0, inplace=True) # replace NA in value column with 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leidens = df[f\"leiden_{res}\"].unique()\n",
    "leidens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.feature.unique()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = []\n",
    "for leiden in leidens:\n",
    "        row = []\n",
    "        msk = df[f\"leiden_{res}\"] == leiden\n",
    "        for f in features:\n",
    "            w, p = ranksums(df.value[df.feature==f][msk], df.value[df.feature==f][~msk], alternative='two-sided')\n",
    "            row.append(p)\n",
    "        row = dc.p_adjust_fdr(row)\n",
    "        pvals.append(row)\n",
    "pvals = pd.DataFrame(pvals, columns=features, index=leidens)\n",
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals.loc[:, :] = np.where(pvals.values < 0.05, '*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby leiden and get the mean per featue\n",
    "df_plot = df.groupby([f\"leiden_{res}\", \"feature\"]).mean().reset_index()\n",
    "# pivot the table\n",
    "df_plot = df_plot.pivot(index=f\"leiden_{res}\", columns=\"feature\", values=\"value\")\n",
    "df_plot.loc[:, :] = zscore(df_plot.values, axis=0, ddof=1)\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color map\n",
    "cmap = plt.get_cmap('coolwarm').copy()\n",
    "cmap.set_bad(color='gray')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), facecolor='white', dpi=125)\n",
    "htm = sns.heatmap(df_plot.T, cmap=cmap, square=True, center=0, vmax=1, vmin=-1, ax=ax, cbar_kws={\"shrink\": .4, \"aspect\": 5},\n",
    "                  annot=pvals.T.values.astype('U'), fmt='', annot_kws={'fontweight': 'black', 'color': 'black'})\n",
    "i = 0\n",
    "for _, spine in htm.spines.items():\n",
    "    if i % 2 == 0:\n",
    "        spine.set_visible(True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average features per cluster\n",
    "for obsm_key in obsm_to_use:\n",
    "    df = adata.obsm[obsm_key].copy()\n",
    "    meta_keys = [\"sample_id\", \"Condition\", \"lesion_type\"] + [\"leiden_\" + str(res) for res in resolutions]\n",
    "    df = df.join(adata.obs[meta_keys], on=\"cell\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.melt(id_vars=[\"cell\"]+meta_keys, var_name=\"feature\", value_name=\"value\")\n",
    "    for res in resolutions:\n",
    "        # TODO: add pvalues here to the heatmaps\n",
    "        # TODO: save the test statistic dataframe\n",
    "        # TODO: change the heatmap color to the one from the preprint\n",
    "        ### start from https://github.com/schae211/VisiumMS/blob/4059a4c8e2af9c39af787ebee1439fc854d311d6/scripts/figures/fig2/heatmap_progeny.py#L30 ###\n",
    "        #leidens = df[f\"leiden_{res}\"].unique()\n",
    "        #pathways = acts.var_names\n",
    "        #pvals = []\n",
    "        #for leiden in leidens:\n",
    "        #    row = []\n",
    "        #    msk = acts.obs['leiden'] == leiden\n",
    "        #    for pathway in pathways:\n",
    "        #        w, p = ranksums(acts[:, pathway][msk].X, acts[:, pathway][~msk].X, alternative='greater')\n",
    "        #        row.append(p[0])\n",
    "        #    row = dc.p_adjust_fdr(row)\n",
    "        #    pvals.append(row)\n",
    "        #pvals = pd.DataFrame(pvals, columns=pathways, index=leidens)\n",
    "        ### end ###\n",
    "        df_tmp = df.groupby([\"feature\", f\"leiden_{res}\"]).mean().reset_index()\n",
    "        df_tmp[\"min_max_value\"] = df_tmp.groupby([\"feature\"]).value.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "        sns.heatmap(data=df_tmp.pivot(index=\"feature\", columns=f\"leiden_{res}\", values=\"value\"), \n",
    "                    cmap=\"viridis\", ax=ax[0])\n",
    "        sns.heatmap(data=df_tmp.pivot(index=\"feature\", columns=f\"leiden_{res}\", values=\"min_max_value\"), \n",
    "                cmap=\"viridis\", ax=ax[1])\n",
    "        ax[0].set_title(\"Raw values\")\n",
    "        ax[1].set_title(\"Min-max scaled values per feature\")\n",
    "        fig.savefig(plot_dir / f\"feature_heatmap_{obsm_key}_res_{res}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature loadings per factor\n",
    "for obsm_key in obsm_to_use:\n",
    "    features = obsm_features[obsm_key]\n",
    "    fig, ax = plt.subplots(figsize=(6, 10))\n",
    "    sns.heatmap(model.get_weights(df=True).loc[features, :], ax=ax, cmap=\"coolwarm\", center=0)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / f\"feature_loadings_{obsm_key}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the fraction of variance explained per group per factor per view\n",
    "fig = mfx.plot.plot_r2(model, y=\"Group\", x=\"Factor\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_dir / \"r2_per_group_per_factor_per_view.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.5\n",
    "df = adata.obs.copy()\n",
    "df = df.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "df += 1 # adding pseudocount otherwise ilr breaks\n",
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "# remove outlier sample MS94\n",
    "df = df.loc[df.index != \"MS94\"]\n",
    "\n",
    "# check closure\n",
    "df.loc[:, :] = closure(df.values)\n",
    "assert np.all(np.isclose(df.values.sum(axis=1), 1))\n",
    "#plt.imshow(df.values)\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "\n",
    "# apply ilr\n",
    "df_ilr = ilr(df.values)\n",
    "\n",
    "#plt.imshow(df_ilr)\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=df_ilr.shape[1])\n",
    "pca.fit(df_ilr)\n",
    "pca_df = pd.DataFrame(pca.transform(df_ilr)[:,[0,1,2,3]], index=df.index, columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\"])\n",
    "pca_df[\"sample_id\"] = pca_df.index.get_level_values(0)\n",
    "pca_df.set_index(\"sample_id\", inplace=True)\n",
    "pca_df = pca_df.join(sample_meta.set_index(\"sample_id\"),  on=\"sample_id\", how=\"left\", lsuffix=\"_pca\", rsuffix=\"_meta\")\n",
    "pca_df = pca_df.reset_index()\n",
    "pca_df.Batch = [str(b) for b in pca_df.Batch]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(14, 12))\n",
    "ax = ax.flatten()\n",
    "for axis, label in zip(ax, [\"Condition\", \"lesion_type\", \"Batch\", \"Sex\", \"Age\", \"lesion_type\"]):\n",
    "    sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=label, ax=axis)\n",
    "    axis.set_title(f\"PCA on Cluster Proportions, colored by {label}\")\n",
    "    axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    axis.set_xlabel(f\"PC1: {np.round(pca.explained_variance_ratio_[0], 2)}\")\n",
    "    axis.set_ylabel(f\"PC2: {np.round(pca.explained_variance_ratio_[1], 2)}\")\n",
    "    fig.tight_layout()\n",
    "    axis.set_aspect('equal', 'box')\n",
    "# plot sample_id labels\n",
    "for string, x, y in zip(pca_df.sample_id, pca_df.PC1, pca_df.PC2):\n",
    "    ax[5].text(x, y, string)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Sample ID\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per sample (resolution {res})\")\n",
    "    plt.show()\n",
    "    #fig.savefig(plot_dir / f\"cluster_fractions_per_sample_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"lesion_type\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Lesion Type\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per lesion type (resolution {res})\")\n",
    "    plt.show()\n",
    "    #fig.savefig(plot_dir / f\"cluster_fractions_per_sample_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"Condition\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Sample ID\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per condition (resolution {res})\")\n",
    "    plt.show()\n",
    "    #fig.savefig(plot_dir / f\"cluster_fractions_per_sample_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key = obsm_to_use[0]\n",
    "df = adata.obsm[obsm_key].copy()\n",
    "meta_keys = [\"sample_id\", \"Condition\", \"lesion_type\"] + [\"leiden_\" + str(res) for res in resolutions]\n",
    "df = df.join(adata.obs[meta_keys], on=\"cell\")\n",
    "df.reset_index(inplace=True)\n",
    "df = df.melt(id_vars=[\"cell\"]+meta_keys, var_name=\"feature\", value_name=\"value\")\n",
    "for res in resolutions:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(data=df.groupby([\"feature\", f\"leiden_{res}\"]).mean().reset_index().\n",
    "                pivot(index=\"feature\", columns=f\"leiden_{res}\", values=\"value\"), \n",
    "                cmap=\"viridis\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key = obsm_to_use[1]\n",
    "df = adata.obsm[obsm_key].copy()\n",
    "meta_keys = [\"sample_id\", \"Condition\", \"lesion_type\"] + [\"leiden_\" + str(res) for res in resolutions]\n",
    "df = df.join(adata.obs[meta_keys], on=\"cell\")\n",
    "df.reset_index(inplace=True)\n",
    "df = df.melt(id_vars=[\"cell\"]+meta_keys, var_name=\"feature\", value_name=\"value\")\n",
    "for res in resolutions:\n",
    "    df_tmp = df.groupby([\"feature\", f\"leiden_{res}\"]).mean().reset_index()\n",
    "    df_tmp[\"min_max_value\"] = df_tmp.groupby([\"feature\"]).value.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "    sns.heatmap(data=df_tmp.pivot(index=\"feature\", columns=f\"leiden_{res}\", values=\"value\"), \n",
    "                cmap=\"viridis\", ax=ax[0])\n",
    "    sns.heatmap(data=df_tmp.pivot(index=\"feature\", columns=f\"leiden_{res}\", values=\"min_max_value\"), \n",
    "            cmap=\"viridis\", ax=ax[1])\n",
    "    ax[0].set_title(\"Raw values\")\n",
    "    ax[1].set_title(\"Min-max scaled values per feature\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key = obsm_to_use[0]\n",
    "df = adata.obsm[obsm_key].copy()\n",
    "df[\"leiden\"] = adata.obs[[\"leiden_0.5\"]]\n",
    "df[\"condition\"] = adata.obs.Condition.values\n",
    "df.reset_index(inplace=True)\n",
    "df = df.melt(id_vars=[\"cell\", \"leiden\", \"condition\"], var_name=\"feature\", value_name=\"value\")\n",
    "\n",
    "# compute mean feature per leiden and plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.barplot(data=df, x=\"value\", y=\"feature\", hue=\"leiden\", ax=ax)\n",
    "ax.set_ylabel(\"Feature\")\n",
    "ax.set_xlabel(\"Mean feature value\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key = obsm_to_use[1]\n",
    "df = adata.obsm[obsm_key].copy()\n",
    "df[\"leiden\"] = adata.obs.leiden.values\n",
    "df[\"condition\"] = adata.obs.condition.values\n",
    "df.reset_index(inplace=True)\n",
    "df = df.melt(id_vars=[\"cell\", \"leiden\", \"condition\"], var_name=\"feature\", value_name=\"value\")\n",
    "\n",
    "# compute mean feature per leiden and plot\n",
    "fig, ax = plt.subplots(figsize=(6, 12))\n",
    "sns.barplot(data=df, x=\"value\", y=\"feature\", hue=\"leiden\", ax=ax)\n",
    "ax.set_ylabel(\"Feature\")\n",
    "ax.set_xlabel(\"Mean feature value\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Loadings per Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_factors().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.heatmap(model.get_weights(df=True).loc[obsm_features[\"abunds_all\"], :], ax=ax, cmap=\"coolwarm\", center=0)\n",
    "plt.show()\n",
    "\n",
    "# same heatmap as above but standardize each column (subtract mean and divide by std)\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "#df = model.get_weights(df=True).loc[obsm_features[\"abunds_all\"], :]\n",
    "#df = df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "#sns.heatmap(df, ax=ax, cmap=\"coolwarm\", center=0)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 10))\n",
    "sns.heatmap(model.get_weights(df=True).loc[obsm_features[\"hallmark_estimates\"], :], ax=ax, cmap=\"coolwarm\", center=0)\n",
    "plt.show()\n",
    "\n",
    "# same heatmap as above but standardize each column (subtract mean and divide by std)\n",
    "#xfig, ax = plt.subplots(1, 1, figsize=(6, 10))\n",
    "#xdf = model.get_weights(df=True).loc[obsm_features[\"hallmark_estimates\"], :]\n",
    "#xdf = df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "#xsns.heatmap(df, ax=ax, cmap=\"coolwarm\", center=0)\n",
    "#xplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Factors per Sample or Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.get_factors(df=True)\n",
    "df[\"sample_id\"] = meta_df.loc[model.get_cells().cell, \"sample_id\"].values\n",
    "df[\"condition\"] = meta_df.loc[model.get_cells().cell, \"condition\"].values\n",
    "df[\"lesion_type\"] = meta_df.loc[model.get_cells().cell, \"lesion_type\"].values\n",
    "df = df.reset_index().melt(id_vars=[\"index\", \"sample_id\", \"condition\", \"lesion_type\"], var_name=\"Factor\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, col=\"Factor\", hue=\"condition\", col_wrap=3, sharex=False, sharey=False, legend_out=True)\n",
    "g.map_dataframe(sns.histplot, x=\"value\", stat=\"density\", common_norm=False, bins=100, alpha=0.5)\n",
    "g.tight_layout()\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = sns.FacetGrid(data=df, row=\"condition\", col=\"Factor\", legend_out=True)\n",
    "#g.map_dataframe(sns.histplot, x=\"value\", stat=\"density\", common_norm=False, bins=100)\n",
    "#g.tight_layout()\n",
    "#g.add_legend()\n",
    "#plt.show()\n",
    "#\n",
    "#g = sns.FacetGrid(data=df, row=\"sample_id\", col=\"Factor\", legend_out=True)\n",
    "#g.map_dataframe(sns.histplot, x=\"value\", stat=\"density\", common_norm=False, bins=100)\n",
    "#g.tight_layout()\n",
    "#g.add_legend()\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the factors are mutally independent?\n",
    "mfx.plot_factors_correlation(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r2 = model.get_r2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfx.plot.plot_r2(model, y=\"Group\", x=\"Factor\")\n",
    "#mfx.plot_r2_barplot(model, factors=list(range(0, 6)), x=\"Group\", groupby=\"Factor\", palette=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group df_r2 by Group and Factor and take the geometric mean of the R2 values\n",
    "stat = df_r2.drop(\"View\", axis=1).groupby([\"Group\", \"Factor\"]).apply(lambda x: np.prod(x)**(1/len(x))).groupby(\"Group\").sum().R2.mean()\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 10))\n",
    "ax = mfx.plot_weights(model, n_features=2, y_repel_coef=0.04, x_rank_offset=-150, views=[\"abunds_all\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 10))\n",
    "ax = mfx.plot_weights(model, n_features=2, y_repel_coef=0.04, x_rank_offset=-150, views=[\"hallmark_estimates\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfx.plot_weights_heatmap(model, n_features=5, view=0,\n",
    "                         factors=range(0, 9), \n",
    "                         xticklabels_size=6, w_abs=True, \n",
    "                         cmap=\"viridis\", cluster_factors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfx.plot_weights_heatmap(model, n_features=5, view=1,\n",
    "                         factors=range(0, 9), \n",
    "                         xticklabels_size=6, w_abs=True, \n",
    "                         cmap=\"viridis\", cluster_factors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfx.plot_weights_dotplot(model, n_features=3, \n",
    "                         w_abs=True, \n",
    "                         factors=list(range(0, 9)), yticklabels_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
