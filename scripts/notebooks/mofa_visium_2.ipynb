{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mofapy2.run.entry_point import entry_point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scanpy as sc\n",
    "import mofax as mfx\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from scipy.stats import ranksums, zscore\n",
    "\n",
    "from composition_stats import closure, ilr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import decoupler as dc\n",
    "import plotnine as pn\n",
    "import argparse\n",
    "\n",
    "output = \"cellbender\"\n",
    "deconv_model = \"all\"\n",
    "dc_model = \"ulm\"\n",
    "ct_metric = \"abunds\"\n",
    "image_features = \"None\"\n",
    "n_factors = 10\n",
    "recompute = True\n",
    "\n",
    "#NOTE: hallmarks are always used\n",
    "obsm_to_use = []\n",
    "#TODO: rerun process and remove this line\n",
    "#obsm_to_use.append(f\"hallmark_{dc_model}_estimates\")\n",
    "if dc_model == \"ulm\":\n",
    "    obsm_to_use.append(\"hallmark_ulm_estimates\") # see here \"estimates\"\n",
    "elif dc_model == \"wmean\":\n",
    "    obsm_to_use.append(\"hallmark_wmean_estimate\") # see here \"estimate\"\n",
    "\n",
    "if image_features != \"None\":\n",
    "    obsm_to_use.append(image_features)\n",
    "\n",
    "obsm_to_use.append(f\"{ct_metric}_{deconv_model}\")\n",
    "\n",
    "print(f\"Using the following views: {obsm_to_use}\")\n",
    "\n",
    "# initialise the entry point\n",
    "ent = entry_point()\n",
    "\n",
    "# set the paths\n",
    "current_path = globals()[\"_dh\"][0]\n",
    "out_dir = current_path / \"..\" / \"..\" / \"data\" / \"prc\" / \"vis\" / \"mofa_tests\" / output / f\"{deconv_model}__{ct_metric}__{dc_model}__{image_features}__{str(n_factors)}\"\n",
    "plot_dir = out_dir / \"plots\"\n",
    "sc.settings.figdir = str(plot_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "plot_dir.mkdir(parents=True, exist_ok=True) \n",
    "visium_path = current_path / \"..\" / \"..\" / \"data\" / \"prc\" / \"vis\" / \"processed\" / output\n",
    "visium_samples = [f.split(\".\")[0] for f in os.listdir(visium_path) if not f.startswith(\".\")]\n",
    "\n",
    "# get visium samples\n",
    "visium_samples = [f.split(\".\")[0] for f in os.listdir(visium_path) if not f.startswith(\".\")]\n",
    "print(np.array(visium_samples))\n",
    "\n",
    "# get the metadata\n",
    "sample_meta = pd.read_excel(current_path / \"..\" / \"..\" / \"data\" / \"Metadata_all.xlsx\", sheet_name=\"Visium\")\n",
    "\n",
    "# load the visium data\n",
    "vis_dict = {smp: sc.read_h5ad(visium_path / f\"{smp}.h5ad\") for smp in visium_samples}\n",
    "\n",
    "# TODO: temporary fix to put the ilr transformed data into a dataframe\n",
    "# NOTE: It is important that the column names do not resemble integers otherwise there are hd5 errors when saving the MOFA model\n",
    "for values in vis_dict.values():\n",
    "    values.obsm[\"props_ilr_all\"] = pd.DataFrame(values.obsm[\"props_ilr_all\"], index=values.obs.index, \n",
    "                                                columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_all\"].shape[1]))])\n",
    "    values.obsm[\"props_ilr_condition\"] = pd.DataFrame(values.obsm[\"props_ilr_condition\"], index=values.obs.index, \n",
    "                                                      columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_condition\"].shape[1]))])\n",
    "    #values.obsm[\"props_ilr_lesion_type\"] = pd.DataFrame(values.obsm[\"props_ilr_lesion_type\"], index=values.obs.index, \n",
    "    #                                                    columns=[\"irl_\" + str(s) for s in list(range(values.obsm[\"props_ilr_lesion_type\"].shape[1]))])\n",
    "\n",
    "# checks\n",
    "print(visium_samples[0])\n",
    "print(f\"Adata object for first visium sample:\\n{vis_dict[visium_samples[0]]}\")\n",
    "print(f\"Available obsm layers:\\n{vis_dict[visium_samples[0]].obsm_keys()}\")\n",
    "obsm_features = {obsm_key: vis_dict[visium_samples[0]].obsm[obsm_key].columns.to_list() for obsm_key in obsm_to_use}\n",
    "\n",
    "# get cell metadata\n",
    "meta_list = []\n",
    "for sample in visium_samples:\n",
    "    df = vis_dict[sample].obs.copy()\n",
    "    df.index = [sample + \"_\" + s for s in df.index]\n",
    "    df[\"sample_id\"] = sample\n",
    "    df[\"condition\"] = sample_meta.loc[sample_meta.sample_id == sample, \"Condition\"].values[0]\n",
    "    df[\"lesion_type\"] = sample_meta.loc[sample_meta.sample_id == sample, \"lesion_type\"].values[0]\n",
    "    meta_list.append(df)\n",
    "meta_df = pd.concat(meta_list, axis=0)\n",
    "\n",
    "# create mofa dataframe\n",
    "df_list = []\n",
    "for obsm_key in obsm_to_use:\n",
    "    for sample in visium_samples:\n",
    "        df = vis_dict[sample].obsm[obsm_key].copy()\n",
    "        df.index = [sample + \"_\" + s for s in df.index] # unique barcodes are required!\n",
    "        df = df.reset_index().melt(id_vars=\"index\", var_name=\"feature\", value_name=\"value\")\n",
    "        df = df.rename(columns={\"index\": \"sample\"})\n",
    "        df[\"group\"] = sample\n",
    "        df[\"view\"] = obsm_key\n",
    "        df = df[[\"sample\", \"group\", \"feature\", \"value\", \"view\"]]\n",
    "        df_list.append(df)\n",
    "data_dt = pd.concat(df_list)\n",
    "print(\"Mofa dataframe:\\n\")\n",
    "print(data_dt.head())\n",
    "print(data_dt.tail())\n",
    "\n",
    "# scale each view to unit variance\n",
    "ent.set_data_options(\n",
    "    scale_views = True\n",
    ")\n",
    "\n",
    "# set the likelihoods for all views\n",
    "ent.set_data_df(data_dt, likelihoods = [\"gaussian\" for _ in range(len(obsm_to_use))])\n",
    "\n",
    "# set the model options\n",
    "ent.set_model_options(\n",
    "    factors = n_factors,\n",
    "    spikeslab_weights = True, \n",
    "    ard_weights = True\n",
    ")\n",
    "\n",
    "# set the training options\n",
    "ent.set_train_options(\n",
    "    convergence_mode = \"fast\", \n",
    "    dropR2 = 0.001, \n",
    "    gpu_mode = True, \n",
    "    seed = 1\n",
    ")\n",
    "\n",
    "ent.build()\n",
    "\n",
    "ent.run()\n",
    "\n",
    "ent.save(outfile=str(out_dir / \"mofa_model.hdf5\"))\n",
    "\n",
    "# downstream part\n",
    "model = mfx.mofa_model(out_dir / \"mofa_model.hdf5\")\n",
    "\n",
    "# verbosity\n",
    "print(f\"\"\"\\\n",
    "Cells: {model.shape[0]}\n",
    "Features: {model.shape[1]}\n",
    "Groups of cells: {', '.join(model.groups)}\n",
    "Views: {', '.join(model.views)}\n",
    "\"\"\")\n",
    "\n",
    "# create adata object based on MOFA results\n",
    "adata = sc.AnnData(X=model.get_factors())\n",
    "adata.obs = model.get_cells()\n",
    "adata.obs.set_index(\"cell\", inplace=True)\n",
    "sc.pp.neighbors(adata, n_neighbors=15, use_rep=\"X\")\n",
    "resolutions = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "for res in resolutions:\n",
    "    sc.tl.leiden(adata, resolution=res, key_added=f\"leiden_{res}\")\n",
    "adata.obs.rename(columns={\"group\": \"sample_id\"}, inplace=True)\n",
    "adata.obs = adata.obs.join(sample_meta.set_index(\"sample_id\"), on=\"sample_id\")\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "for obsm_key in obsm_to_use:\n",
    "    df_list = []\n",
    "    for sample in visium_samples:\n",
    "        df = vis_dict[sample].obsm[obsm_key].copy()\n",
    "        df.index = [sample + \"_\" + s for s in df.index] # unique barcodes are required!\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list)\n",
    "    adata.obsm[obsm_key] = df.loc[adata.obs_names]\n",
    "\n",
    "adata.write(out_dir / \"adata.h5ad\")\n",
    "\n",
    "# check umaps\n",
    "sc.pl.umap(adata, color=[\"sample_id\", \"Condition\", \"leiden_0.5\"], ncols=1, save=\".pdf\", show=False)\n",
    "\n",
    "# count the cluster fractions per sample, pca, and visualize\n",
    "for res in resolutions:\n",
    "    df = adata.obs.copy()\n",
    "    df = df.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df += 1 # adding pseudocount otherwise ilr breaks (returns NA)\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "    # remove outlier sample MS94\n",
    "    df = df.loc[df.index != \"MS94\"]\n",
    "\n",
    "    # apply ilr (first check and ensure closure)\n",
    "    df.loc[:, :] = closure(df.values)\n",
    "    assert np.all(np.isclose(df.values.sum(axis=1), 1))\n",
    "    df_ilr = ilr(df.values)\n",
    "\n",
    "    pca = PCA(n_components=df_ilr.shape[1])\n",
    "    pca.fit(df_ilr)\n",
    "    pca_df = pd.DataFrame(pca.transform(df_ilr)[:,[0,1,2,3]], index=df.index, columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\"])\n",
    "    pca_df[\"sample_id\"] = pca_df.index.get_level_values(0)\n",
    "    pca_df.set_index(\"sample_id\", inplace=True)\n",
    "    pca_df = pca_df.join(sample_meta.set_index(\"sample_id\"),  on=\"sample_id\", how=\"left\", lsuffix=\"_pca\", rsuffix=\"_meta\")\n",
    "    pca_df = pca_df.reset_index()\n",
    "    pca_df.Batch = [str(b) for b in pca_df.Batch]\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(14, 12))\n",
    "    ax = ax.flatten()\n",
    "    for axis, label in zip(ax, [\"Condition\", \"lesion_type\", \"Batch\", \"Sex\", \"Age\", \"lesion_type\"]):\n",
    "        sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=label, ax=axis)\n",
    "        axis.set_title(f\"PCA on Cluster Proportions, colored by {label}\")\n",
    "        axis.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        axis.set_xlabel(f\"PC1: {np.round(pca.explained_variance_ratio_[0], 2)}\")\n",
    "        axis.set_ylabel(f\"PC2: {np.round(pca.explained_variance_ratio_[1], 2)}\")\n",
    "        fig.tight_layout()\n",
    "        axis.set_aspect('equal', 'box')\n",
    "    # plot sample_id labels\n",
    "    for string, x, y in zip(pca_df.sample_id, pca_df.PC1, pca_df.PC2):\n",
    "        ax[5].text(x, y, string)\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_pca_{res}.pdf\")\n",
    "\n",
    "# count the cluster fractions per sample, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"sample_id\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Sample ID\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per sample (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_sample_heatmap_res_{res}.pdf\")\n",
    "\n",
    "# count the cluster fractions per lesion type, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"lesion_type\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Lesion Type\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per lesion type (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_lesion_type_heatmap_res_{res}.pdf\")\n",
    "\n",
    "# count the cluster fractions per condition, divide by the rowsums\n",
    "for res in resolutions:\n",
    "    df = adata.obs.groupby([\"Condition\", f\"leiden_{res}\"]).size().unstack()\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))\n",
    "    sns.heatmap(df, cmap=\"viridis\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Condition\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Cluster fractions per condition (resolution {res})\")\n",
    "    fig.savefig(plot_dir / f\"cluster_fractions_per_condition_heatmap_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average features per cluster\n",
    "for obsm_key in obsm_to_use:\n",
    "    print(obsm_key)\n",
    "    df = adata.obsm[obsm_key].copy()\n",
    "    meta_keys = [\"sample_id\", \"Condition\", \"lesion_type\"] + [\"leiden_\" + str(res) for res in resolutions]\n",
    "    df = df.join(adata.obs[meta_keys], on=\"cell\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.melt(id_vars=[\"cell\"]+meta_keys, var_name=\"feature\", value_name=\"value\")\n",
    "    assert df.value.isna().sum() == 0\n",
    "    if \"abunds\" in obsm_key:\n",
    "        # use proportions instead of abundances for cell types\n",
    "        df[\"value\"] = df.groupby([\"cell\"])[\"value\"].transform(lambda x: x / x.sum())\n",
    "    for res in resolutions:\n",
    "        # get niches and features\n",
    "        leidens, features = df[f\"leiden_{res}\"].unique(), df.feature.unique()\n",
    "        print(res)\n",
    "        df_tmp = df.groupby([\"sample_id\", f\"leiden_{res}\", \"feature\"]).mean().reset_index()\n",
    "        df_tmp.value.fillna(0, inplace=True) # replace NA in value column with 0\n",
    "\n",
    "        # compute p-values using ranksums test\n",
    "        pvals = []\n",
    "        for leiden in leidens:\n",
    "                row = []\n",
    "                msk = df_tmp[f\"leiden_{res}\"] == leiden\n",
    "                for f in features:\n",
    "                    w, p = ranksums(df_tmp.value[df_tmp.feature==f][msk], df_tmp.value[df_tmp.feature==f][~msk], alternative='two-sided')\n",
    "                    row.append(p)\n",
    "                row = dc.p_adjust_fdr(row)\n",
    "                pvals.append(row)\n",
    "        pvals = pd.DataFrame(pvals, columns=features, index=leidens)\n",
    "\n",
    "        pvals.loc[:, :] = np.where(pvals.values < 0.05, '*', '')\n",
    "\n",
    "        df_plot = df_tmp.groupby([f\"leiden_{res}\", \"feature\"]).mean().reset_index()\n",
    "        df_plot = df_plot.pivot(index=f\"leiden_{res}\", columns=\"feature\", values=\"value\")\n",
    "        df_plot.loc[:, :] = zscore(df_plot.values, axis=0, ddof=1)\n",
    "\n",
    "        cmap = plt.get_cmap('coolwarm').copy()\n",
    "        cmap.set_bad(color='gray')\n",
    "        \n",
    "        if (\"abunds\" in obsm_key)or (\"ilr\" in obsm_key):\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 6), facecolor='white', dpi=125)\n",
    "        else:\n",
    "             fig, ax = plt.subplots(1, 1, figsize=(24, 12), facecolor='white', dpi=125)\n",
    "        htm = sns.heatmap(df_plot.T, cmap=cmap, square=True, center=0, vmax=1, vmin=-1, ax=ax, cbar_kws={\"shrink\": .4, \"aspect\": 5},\n",
    "                        annot=pvals.T.values.astype('U'), fmt='', annot_kws={'fontweight': 'black', 'color': 'black'})\n",
    "        i = 0\n",
    "        for _, spine in htm.spines.items():\n",
    "            if i % 2 == 0:\n",
    "                spine.set_visible(True)\n",
    "            i += 1\n",
    "\n",
    "        fig.savefig(plot_dir / f\"feature_heatmap_{obsm_key}_res_{res}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
